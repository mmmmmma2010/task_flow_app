services:
  # PostgreSQL Database
  - type: pserv
    name: taskflow-db
    plan: starter
    region: oregon
    databaseName: taskflow_db
    user: taskflow_user
    ipAllowList: []

  # Redis (Cache + Celery Broker)
  - type: redis
    name: taskflow-redis
    plan: starter
    region: oregon
    maxmemoryPolicy: allkeys-lru
    ipAllowList: []

  # Django Web Service
  - type: web
    name: taskflow-web
    env: docker
    plan: starter
    region: oregon
    dockerfilePath: ./Dockerfile
    dockerContext: .
    healthCheckPath: /api/health/

    envVars:
      - key: DJANGO_SETTINGS_MODULE
        value: config.settings.production

      - key: SECRET_KEY
        generateValue: true

      - key: DEBUG
        value: "False"

      - key: ALLOWED_HOSTS
        value: taskflow-web.onrender.com,.onrender.com

      - key: DATABASE_URL
        fromDatabase:
          name: taskflow-db
          property: connectionString

      - key: REDIS_URL
        fromService:
          name: taskflow-redis
          type: redis
          property: connectionString

      - key: CELERY_BROKER_URL
        fromService:
          name: taskflow-redis
          type: redis
          property: connectionString

      - key: CELERY_RESULT_BACKEND
        fromService:
          name: taskflow-redis
          type: redis
          property: connectionString

      # Email configuration (add manually after deployment)
      - key: EMAIL_HOST_USER
        sync: false
      - key: EMAIL_HOST_PASSWORD
        sync: false

      # Optional: Sentry for error tracking
      - key: SENTRY_DSN
        sync: false

      # Gunicorn configuration
      - key: GUNICORN_WORKERS
        value: "2"
      - key: GUNICORN_THREADS
        value: "4"
      - key: GUNICORN_TIMEOUT
        value: "120"

    buildCommand: |
      pip install --upgrade pip
      pip install -r requirements/production.txt
      python manage.py collectstatic --noinput --clear

    startCommand: |
      python manage.py migrate --noinput
      gunicorn config.wsgi:application \
        --bind 0.0.0.0:$PORT \
        --workers ${GUNICORN_WORKERS:-2} \
        --threads ${GUNICORN_THREADS:-4} \
        --worker-class sync \
        --worker-tmp-dir /dev/shm \
        --timeout ${GUNICORN_TIMEOUT:-120} \
        --graceful-timeout 30 \
        --keep-alive 5 \
        --max-requests 1000 \
        --max-requests-jitter 50 \
        --access-logfile - \
        --error-logfile - \
        --log-level info \
        --capture-output

  # Celery Worker
  - type: worker
    name: taskflow-celery-worker
    env: docker
    plan: starter
    region: oregon
    dockerfilePath: ./Dockerfile
    dockerContext: .

    envVars:
      - key: DJANGO_SETTINGS_MODULE
        value: config.settings.production
      - key: SECRET_KEY
        fromService:
          name: taskflow-web
          type: web
          envVarKey: SECRET_KEY
      - key: DATABASE_URL
        fromDatabase:
          name: taskflow-db
          property: connectionString
      - key: CELERY_BROKER_URL
        fromService:
          name: taskflow-redis
          type: redis
          property: connectionString
      - key: CELERY_RESULT_BACKEND
        fromService:
          name: taskflow-redis
          type: redis
          property: connectionString
      - key: CELERY_CONCURRENCY
        value: "2"

    startCommand: |
      celery -A config worker \
        --loglevel=info \
        --concurrency=${CELERY_CONCURRENCY:-2} \
        --max-tasks-per-child=1000 \
        --time-limit=300 \
        --soft-time-limit=270

  # Celery Beat (Periodic Tasks)
  - type: worker
    name: taskflow-celery-beat
    env: docker
    plan: starter
    region: oregon
    dockerfilePath: ./Dockerfile
    dockerContext: .

    envVars:
      - key: DJANGO_SETTINGS_MODULE
        value: config.settings.production
      - key: SECRET_KEY
        fromService:
          name: taskflow-web
          type: web
          envVarKey: SECRET_KEY
      - key: DATABASE_URL
        fromDatabase:
          name: taskflow-db
          property: connectionString
      - key: REDIS_URL
        fromService:
          name: taskflow-redis
          type: redis
          property: connectionString

    startCommand: |
      celery -A config beat \
        --loglevel=info \
        --scheduler django_celery_beat.schedulers:DatabaseScheduler \
        --pidfile=/tmp/celerybeat.pid

databases:
  - name: taskflow-db
    databaseName: taskflow_db
    user: taskflow_user
    plan: starter
    region: oregon
