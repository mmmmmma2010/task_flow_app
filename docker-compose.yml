version: '3.8'

services:
  # PostgreSQL Database
  db:
    image: postgres:15-alpine
    container_name: taskflow_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=${DB_NAME:-taskflow_db}
      - POSTGRES_USER=${DB_USER:-taskflow_user}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-taskflow_pass}
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-taskflow_user} -d ${DB_NAME:-taskflow_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - taskflow_network

  # Redis for caching and Celery broker
  redis:
    image: redis:7-alpine
    container_name: taskflow_redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - taskflow_network

  # Django Web Application
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: taskflow_web
    command: gunicorn config.wsgi:application --bind 0.0.0.0:8000 --workers 3 --timeout 120
    volumes:
      - .:/app
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.development
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - taskflow_network
    restart: unless-stopped

  # Celery Worker for background tasks
  celery_worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: taskflow_celery_worker
    command: celery -A config worker --loglevel=info --concurrency=2
    volumes:
      - .:/app
    env_file:
      - .env
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.development
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - taskflow_network
    restart: unless-stopped

  # Celery Beat for periodic tasks
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: taskflow_celery_beat
    command: celery -A config beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    volumes:
      - .:/app
    env_file:
      - .env
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.development
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - taskflow_network
    restart: unless-stopped



volumes:
  postgres_data:
  redis_data:

networks:
  taskflow_network:
    driver: bridge
